import streamlit as st
import pandas as pd

from sklearn.metrics import (
    accuracy_score, roc_auc_score, precision_score,
    recall_score, f1_score, matthews_corrcoef,
    confusion_matrix, classification_report
)

from model.dataset_loader import load_dataset
from model.logistic_regression import get_model as lr_model
from model.decision_tree import get_model as dt_model
from model.knn import get_model as knn_model
from model.naive_bayes import get_model as nb_model
from model.random_forest import get_model as rf_model
from model.xgboost_model import get_model as xgb_model

# Model definition set up
MODEL_REGISTRY = {
    "Logistic Regression": lr_model,
    "Decision Tree": dt_model,
    "KNN": knn_model,
    "Naive Bayes": nb_model,
    "Random Forest": rf_model,
    "XGBoost": xgb_model
}


# Evaluation Function

def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)

    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test)[:, 1]
        auc = roc_auc_score(y_test, y_prob)
    else:
        auc = None

    results = {
        "Accuracy": accuracy_score(y_test, y_pred),
        "AUC": auc,
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1 Score": f1_score(y_test, y_pred),
        "MCC": matthews_corrcoef(y_test, y_pred)
    }

    return results, y_pred


# Streamlit UI Dashboard:
def main():
    st.set_page_config(page_title="ML Model Dashboard", layout="wide")
    st.title("ML Classification Model Dashboard")
    st.write("Upload test dataset, select model, and evaluate performance.")

    st.subheader(" Upload Test Dataset  csv fine only(.CSV format)")
    uploaded_file = st.file_uploader("Upload CSV file (Test Data Only)", type=["csv"])

# Choose Model

    st.subheader("choose the Model")
    selected_model_name = st.selectbox("choose the Model", list(MODEL_REGISTRY.keys()))

# Run Evaluation
    if st.button("Run Evaluation"):

        if uploaded_file is None:
            st.error(" Please upload a CSV test dataset only.")
            return

        with st.spinner("Loading model and evaluating..."):

            # Load test dataset
            test_df = pd.read_csv(uploaded_file)

            if "target" not in test_df.columns:
                st.error(" CSV file must contain a 'target' column.")
                return

            X_test = test_df.drop("target", axis=1)
            y_test = test_df["target"]

            # Load training dataset and train model
            X_train, _, y_train, _ = load_dataset()

            model = MODEL_REGISTRY[selected_model_name]()
            model.fit(X_train, y_train)

            # Evaluate
            results, y_pred = evaluate_model(model, X_test, y_test)


# Display Metrics
        st.success(" Model evaluation completed successfully!")

        st.subheader("Evaluation Metrics")
        metrics_df = pd.DataFrame(results.items(), columns=["Metric", "Value"])
        st.table(metrics_df)

# Confusion Matrix

        st.subheader("Confusion Matrix")
        cm = confusion_matrix(y_test, y_pred)
        cm_df = pd.DataFrame(cm, columns=["Predicted 0", "Predicted 1"], index=["Actual 0", "Actual 1"])
        st.dataframe(cm_df)

# Classification Report

        st.subheader(" Classification Report")
        report = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report).transpose()
        st.dataframe(report_df)

# Download Metrics

        st.subheader(" Download Evaluation Report")
        csv = metrics_df.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="Download Metrics CSV",
            data=csv,
            file_name="model_evaluation_metrics.csv",
            mime="text/csv"
        )


if __name__ == "__main__":
    main()
